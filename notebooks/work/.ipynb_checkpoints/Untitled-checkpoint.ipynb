{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdd5f78f-b94f-40d0-abbf-959fb9e267cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aef4ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('Ingest checkin table into bronze') \\\n",
    "    .master('spark://spark-master:7077') \\\n",
    "    .config(\"hive.metastore.uris\", \"thrift://hive-metastore:9083\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", 'minio') \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", 'minio123') \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", 'minio:9000')\\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\\\n",
    "    .config('spark.hadoop.fs.s3a.aws.credentials.provider', 'org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider')\\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n",
    "    .config('spark.sql.warehouse.dir', f's3a://lakehouse/')\\\n",
    "    .config(\n",
    "                \"spark.jars\",\n",
    "                \"/usr/local/spark/jars/delta-core_2.12-2.3.0.jar,/usr/local/spark/jars/hadoop-aws-3.3.2.jar,/usr/local/spark/jars/delta-storage-2.3.0.jar,/usr/local/spark/jars/aws-java-sdk-1.12.367.jar,/usr/local/spark/jars/s3-2.18.41.jar,/usr/local/spark/jars/aws-java-sdk-bundle-1.11.1026.jar\",\n",
    "            )\\\n",
    "    .config('spark.driver.extraClassPath', '/usr/local/spark/jars/hadoop-aws-3.3.2.jar:/usr/local/spark/jars/s3-2.18.41.jar/usr/local/spark/jars/aws-java-sdk-1.12.367.jar/usr/local/spark/jars/delta-core_2.12-2.3.0.jar/usr/local/spark/jars/delta-storage-2.3.0.jar')\\\n",
    "    .config('spark.executor.extraClassPath', '/usr/local/spark/jars/hadoop-aws-3.3.2.jar:/usr/local/spark/jars/s3-2.18.41.jar/usr/local/spark/jars/aws-java-sdk-1.12.367.jar/usr/local/spark/jars/delta-core_2.12-2.3.0.jar/usr/local/spark/jars/delta-storage-2.3.0.jar')\\\n",
    "    .enableHiveSupport()\\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ab709c-c234-4362-a542-ad6e1820493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3def1975-822a-412f-bc35-a2ef6dd95c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('show schemas').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abff33a7-cce4-4179-a4ee-43ad39afd3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('create external TABLE db.test3 (name String) using delta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33eeecb7-9623-4892-a3ab-472562d1ff60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('create schema if not exists db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53692972-ab85-40db-a812-140d59a986ce",
   "metadata": {},
   "outputs": [],
   "source": [
    ".config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15788d28-bad5-480e-86d8-e591aba710dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('show tables in db').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8065c84-7599-4349-98c1-e83a589ad680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "hiveConf = spark._jsparkSession.sessionState().newHadoopConf()\n",
    "hiveMetastoreURI = hiveConf.get(\"javax.jdo.option.ConnectionURL\")\n",
    "print(hiveMetastoreURI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed297e85-479f-49ec-9b5d-0ab9d75e7d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c2706e7-bb2c-42c3-bd7b-78a219fea6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = spark.read \\\n",
    "    .format(\"parquet\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .load(\"s3a://lakehouse/bronze/customer/customer.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ddf0275-6a06-4866-9924-a62829d5f8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.write.format('delta').saveAsTable('db.test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ade6d6aa-4d24-4963-8771-6827af6fb6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------------+--------------------+--------------+\n",
      "|         customer_id|  customer_unique_id|customer_zip_code_prefix|       customer_city|customer_state|\n",
      "+--------------------+--------------------+------------------------+--------------------+--------------+\n",
      "|00012a2ce6f8dcda2...|248ffe10d632bebe4...|                    6273|              osasco|            SP|\n",
      "|000161a058600d590...|b0015e09bb4b6e47c...|                   35550|         itapecerica|            MG|\n",
      "|0001fd6190edaaf88...|94b11d37cd61cb299...|                   29830|        nova venecia|            ES|\n",
      "|0002414f953443074...|4893ad4ea28b2c5b3...|                   39664|            mendonca|            MG|\n",
      "|000379cdec6255224...|0b83f73b19c2019e1...|                    4841|           sao paulo|            SP|\n",
      "|0004164d20a9e969a...|104bdb7e6a6cdceaa...|                   13272|            valinhos|            SP|\n",
      "|000419c5494106c30...|14843983d4a159080...|                   24220|             niteroi|            RJ|\n",
      "|00046a560d407e99b...|0b5295fc9819d831f...|                   20540|      rio de janeiro|            RJ|\n",
      "|00050bf6e01e69d5c...|e3cf594a99e810f58...|                   98700|                ijui|            RS|\n",
      "|000598caf2ef41174...|7e0516b486e92ed3f...|                   35540|            oliveira|            MG|\n",
      "|0005aefbb696d34b3...|616309b2eeb7bd9c0...|                    3052|           sao paulo|            SP|\n",
      "|00062b33cb9f6fe97...|f90f55ee274a4ae21...|                    2306|           sao paulo|            SP|\n",
      "|00066ccbe787a588c...|15090f48004f3b0fc...|                   93525|       novo hamburgo|            RS|\n",
      "|00072d033fe2e5906...|b7c13491fd2aecd93...|                   45026|vitoria da conquista|            BA|\n",
      "|0009a69b72033b2d0...|fa30145b07cad8e97...|                   13106|            campinas|            SP|\n",
      "|000bf8121c3412d30...|1bc9b2dad6aefbfbc...|                   12335|             jacarei|            SP|\n",
      "|000e943451fc2788c...|d73c3cf4a0922ece1...|                   99460|            colorado|            RS|\n",
      "|000f17e290c26b285...|74541fbb7526dabec...|                   98400|frederico westphalen|            RS|\n",
      "|000fd45d6fedae68f...|cee6fa72fb403ef95...|                   12970|            piracaia|            SP|\n",
      "|0010068a73b7c56da...|03dabd77cb0ed7a26...|                   63680|             parambu|            CE|\n",
      "+--------------------+--------------------+------------------------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dad0ded1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|   bronze|\n",
      "|  default|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS bronze\")\n",
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ce9747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da6cd373",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Table bronze.restaurant_transform already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriteTo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbronze.restaurant_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43musing\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdelta\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/readwriter.py:1431\u001b[0m, in \u001b[0;36mDataFrameWriterV2.create\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1423\u001b[0m \u001b[38;5;129m@since\u001b[39m(\u001b[38;5;241m3.1\u001b[39m)\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1425\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;124;03m    Create a new table from the contents of the data frame.\u001b[39;00m\n\u001b[1;32m   1427\u001b[0m \n\u001b[1;32m   1428\u001b[0m \u001b[38;5;124;03m    The new table's schema, partition layout, properties, and other configuration will be\u001b[39;00m\n\u001b[1;32m   1429\u001b[0m \u001b[38;5;124;03m    based on the configuration set on this writer.\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1431\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Table bronze.restaurant_transform already exists"
     ]
    }
   ],
   "source": [
    "t.writeTo(\"bronze.restaurant_transform\").using('delta').create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "264b6e27-2cfe-4e98-9d58-6c817b674aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|      db1|     test|      false|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"db1.test\")\n",
    "spark.sql(\"SHOW TABLES IN db1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64cc48cd-8c48-4eda-9af2-60e1615f08e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------------+-------------+--------------+\n",
      "|         customer_id|  customer_unique_id|customer_zip_code_prefix|customer_city|customer_state|\n",
      "+--------------------+--------------------+------------------------+-------------+--------------+\n",
      "|00012a2ce6f8dcda2...|248ffe10d632bebe4...|                    6273|       osasco|          SP\\r|\n",
      "|000161a058600d590...|b0015e09bb4b6e47c...|                   35550|  itapecerica|          MG\\r|\n",
      "|0001fd6190edaaf88...|94b11d37cd61cb299...|                   29830| nova venecia|          ES\\r|\n",
      "|0002414f953443074...|4893ad4ea28b2c5b3...|                   39664|     mendonca|          MG\\r|\n",
      "|000379cdec6255224...|0b83f73b19c2019e1...|                    4841|    sao paulo|          SP\\r|\n",
      "+--------------------+--------------------+------------------------+-------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t=\"silver.cleaned_customers\"\n",
    "deltadf = spark.read.format(\"delta\").load(\"s3a://lakehouse/silver.db/cleaned_customers\")\n",
    "deltadf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b13936a-a996-4227-be94-ab8e1ccd2302",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=\"silver.cleaned_customers\"\n",
    "df = spark.read.table(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "001c9d8e-cf66-4925-a43b-42cf3af87b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------------+--------------+--------------+\n",
      "|         customer_id|  customer_unique_id|customer_zip_code_prefix| customer_city|customer_state|\n",
      "+--------------------+--------------------+------------------------+--------------+--------------+\n",
      "|00012a2ce6f8dcda2...|248ffe10d632bebe4...|                    6273|        osasco|          SP\\r|\n",
      "|000161a058600d590...|b0015e09bb4b6e47c...|                   35550|   itapecerica|          MG\\r|\n",
      "|0001fd6190edaaf88...|94b11d37cd61cb299...|                   29830|  nova venecia|          ES\\r|\n",
      "|0002414f953443074...|4893ad4ea28b2c5b3...|                   39664|      mendonca|          MG\\r|\n",
      "|000379cdec6255224...|0b83f73b19c2019e1...|                    4841|     sao paulo|          SP\\r|\n",
      "|0004164d20a9e969a...|104bdb7e6a6cdceaa...|                   13272|      valinhos|          SP\\r|\n",
      "|000419c5494106c30...|14843983d4a159080...|                   24220|       niteroi|          RJ\\r|\n",
      "|00046a560d407e99b...|0b5295fc9819d831f...|                   20540|rio de janeiro|          RJ\\r|\n",
      "|00050bf6e01e69d5c...|e3cf594a99e810f58...|                   98700|          ijui|          RS\\r|\n",
      "|000598caf2ef41174...|7e0516b486e92ed3f...|                   35540|      oliveira|          MG\\r|\n",
      "+--------------------+--------------------+------------------------+--------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5d7c0e-cada-48e7-9071-625063ce1ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
