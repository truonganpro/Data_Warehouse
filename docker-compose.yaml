services:
  # MySQL Service
  de_mysql:
    image: mysql:8.0
    container_name: de_mysql
    volumes:
      - ./mysql:/var/lib/mysql
    ports:
      - "3306:3306"
    env_file:
      - .env
    networks:
      - de_network

  # PostgreSQL Service
  de_psql:
    image: postgres:15
    container_name: de_psql
    volumes:
      - ./postgresql:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    env_file:
      - .env
    networks:
      - de_network

  # Spark Master Node
  spark-master:
    build:
      context: ./docker_image/spark
      dockerfile: ./Dockerfile
    container_name: spark-master
    ports:
      - "7077:7077"  # Spark master port
      - "8081:8080"  # Spark master web UI port
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    volumes:
      - ./docker_image/spark/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./docker_image/spark/conf/log4j.properties:/opt/bitnami/spark/conf/log4j.properties
    networks:
      - de_network

  # Spark Worker Node
  spark-worker-1:
    image: docker.io/bitnami/spark:3.3.2
    container_name: spark-worker-1
    depends_on:
      - spark-master
    env_file:
      - .env
    environment:
      - SPARK_WORKER_MEMORY=1g
      - SPARK_WORKER_CORES=1
      - SPARK_MASTER_URL=spark://spark-master:7077
    networks:
      - de_network

  # Jupyter Notebook for Spark
  spark-notebook:
    build: 
      context: ./notebooks
      dockerfile: ./Dockerfile
    container_name: spark-notebook
    user: root
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - GRANT_SUDO=yes
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000/ 
      - AWS_ACCESS_KEY_ID=minio
      - AWS_SECRET_ACCESS_KEY=minio123
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./docker_image/spark/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./docker_image/spark/conf/log4j.properties:/opt/bitnami/spark/conf/log4j.properties
    ports:
      - "8888:8888"
      - "4040:4040"
    networks:
      - de_network 
  streamlit:
    container_name: streamlit
    build:
      context: ./docker_image/streamlit
      dockerfile: Dockerfile
    image: streamlit:latest
    ports:
      - "8501:8501"
    environment:
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=minio
      - AWS_SECRET_ACCESS_KEY=minio123
    volumes:
      - ./app:/app
    networks:
      - de_network 

  metabase:
    image: metabase/metabase:latest
    container_name: metabase  
    hostname: metabase
    ports:
      - "3000:3000"
    platform: linux/amd64 
    environment:
      MB_DB_TYPE: mysql
      MB_DB_DBNAME: brazillian_ecommerce
      MB_DB_HOST: de_mysql
      MB_DB_PORT: 3306
      MB_DB_USER: admin
      MB_DB_PASS: admin123
      MB_DB_EXTRA_OPTS: "?useSSL=false&allowPublicKeyRetrieval=true"
    networks:
      - de_network
    env_file:
      - .env
    healthcheck:
      test: ["CMD", "curl", "--fail", "-I", "http://localhost:3000/api/health"]
      interval: 15s
      timeout: 5s
      retries: 5

  # MinIO for Storage
  minio:
    hostname: minio
    image: minio/minio
    container_name: minio
    ports:
      - "9001:9001"
      - "9000:9000"
    command: ["server", "/data", "--console-address", ":9001"]
    volumes:
      - ./minio:/data
    env_file:
      - .env
    networks:
      - de_network
 
  # MinIO Client
  mc:
    image: minio/mc
    container_name: mc
    hostname: mc
    env_file:
      - .env
    entrypoint: >
      /bin/sh -c "until (/usr/bin/mc config host add minio http://minio:9000 minio minio123) do echo '...waiting...' && sleep 1; done; /usr/bin/mc mb minio/warehouse; /usr/bin/mc policy set public minio/warehouse; exit 0;"
    depends_on:
      - minio
    networks:
      - de_network

  # ETL Pipeline Service
  etl_pipeline:
    build:
      context: ./etl_pipeline
      dockerfile: ./Dockerfile
    container_name: etl_pipeline
    image: etl_pipeline:latest
    ports:
      - "4000:4000"
      - "4500:4500"
    volumes:
      - ./etl_pipeline:/opt/dagster/app
    env_file:
      - .env
    networks:
      - de_network

  # Dagster Core
  de_dagster:
    build:
      context: ./dagster/
    container_name: de_dagster
    networks:
      - de_network
    ports:
      - "5001:5000"  # Map external port 5001 to internal 5000
    env_file:
      - .env

  # Dagster UI (Dagit)
  de_dagster_dagit:
    build:  # Dùng build thay vì image
      context: ./dagster/
    depends_on:
      - de_dagster
    entrypoint:
      - dagit
      - -h
      - "0.0.0.0"
      - -p
      - "3001"
      - -w
      - workspace.yaml
    container_name: de_dagster_dagit
    ports:
      - "3001:3001"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./dagster_home:/opt/dagster/dagster_home
    env_file:
      - .env
    networks:
      - de_network

  de_dagster_daemon:
    build:  # Dùng build thay vì image
      context: ./dagster/
    depends_on:
      - de_dagster
    entrypoint:
      - dagster-daemon
      - run
    container_name: de_dagster_daemon
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./dagster_home:/opt/dagster/dagster_home
    env_file:
      - .env
    networks:
      - de_network

networks:
  de_network:
    driver: bridge